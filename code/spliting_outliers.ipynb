{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a901ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming raw_data is the folder path containing the CSV file\n",
    "file_name_kadar_air = \"nir_basah_kadar_air_df.csv\"  # Replace with the actual file name\n",
    "file_path_kadar_air = os.path.join(\"./../curated_data_2\", file_name_kadar_air)\n",
    "data_kadar_air = pd.read_csv(file_path_kadar_air)\n",
    "data_kadar_air.head()\n",
    "\n",
    "# Assuming raw_data is the folder path containing the CSV file\n",
    "file_name_gula_reduksi = \"nir_basah_gula_reduksi_df.csv\"  # Replace with the actual file name\n",
    "file_path_gula_reduksi = os.path.join(\"./../curated_data_2\", file_name_gula_reduksi)\n",
    "data_gula_reduksi = pd.read_csv(file_path_gula_reduksi)\n",
    "data_gula_reduksi.head()\n",
    "\n",
    "# Assuming raw_data is the folder path containing the CSV file\n",
    "file_name_lemak = \"nir_basah_lemak_df.csv\"  # Replace with the actual file name\n",
    "file_path_lemak = os.path.join(\"./../curated_data_2\", file_name_lemak)\n",
    "data_lemak = pd.read_csv(file_path_lemak)\n",
    "data_lemak.head()\n",
    "\n",
    "# Assuming raw_data is the folder path containing the CSV file\n",
    "file_name_protein = \"nir_basah_protein_df.csv\"  # Replace with the actual file name\n",
    "file_path_protein = os.path.join(\"./../curated_data_2\", file_name_protein)\n",
    "data_protein = pd.read_csv(file_path_protein)\n",
    "\n",
    "# Assuming raw_data is the folder path containing the CSV file\n",
    "file_name_fenol = \"nir_basah_fenol_df.csv\"  # Replace with the actual file name\n",
    "file_path_fenol = os.path.join(\"./../curated_data_2\", file_name_fenol)\n",
    "data_fenol = pd.read_csv(file_path_fenol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kadar_air = data_kadar_air.drop(columns=['SAMPEL'])\n",
    "data_gula_reduksi = data_gula_reduksi.drop(columns=['SAMPEL'])\n",
    "data_lemak = data_lemak.drop(columns=['SAMPEL' ])\n",
    "data_protein = data_protein.drop(columns=['SAMPEL' ])\n",
    "data_fenol = data_fenol.drop(columns=['SAMPEL' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6401dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns if they exist in any DataFrame in the notebook\n",
    "cols_to_remove = ['abs_error', 'y_cv_pred','y_pred',\"ABS_ERROR\",'y_actual','y_pred_OOF','y_pred_full']\n",
    "\n",
    "df_names = [\n",
    "    'data_kadar_air', 'data_gula_reduksi', 'data_lemak',  \n",
    "    'data_protein', 'data_fenol',\n",
    "]\n",
    "\n",
    "for name in df_names:\n",
    "    if name in globals():\n",
    "        obj = globals()[name]\n",
    "        if isinstance(obj, pd.DataFrame):\n",
    "            # drop columns if present, ignore otherwise\n",
    "            obj.drop(columns=cols_to_remove, inplace=True, errors='ignore')\n",
    "            globals()[name] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../tools')\n",
    "from split_data import datasplit_simple\n",
    "\n",
    "# Contoh penggunaan fungsi datasplit_simple\n",
    "# Misalnya, jika fungsi ini memerlukan parameter seperti data dan rasio split\n",
    "test_data_kadar_air,train_data_kadar_air= datasplit_simple(data_kadar_air, cs=0.2)\n",
    "test_data_gula_reduksi,train_data_gula_reduksi= datasplit_simple(data_gula_reduksi, cs=0.2)\n",
    "test_data_lemak,train_data_lemak= datasplit_simple(data_lemak, cs=0.2)\n",
    "test_data_protein,train_data_protein= datasplit_simple(data_protein, cs=0.2)\n",
    "test_data_fenol,train_data_fenol= datasplit_simple(data_fenol, cs=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca data dari file Wavelenght_NIR.csv\n",
    "wavelength_data = pd.read_csv('../raw_data/Wavelenght_NIR.csv', header=None)\n",
    "wavelength_data = wavelength_data.iloc[:train_data_protein.shape[1], :]  # Potong wavelength_data jika perlu\n",
    "\n",
    "# Tambahkan kolom 'Gula Reduksi' jika belum ada\n",
    "if wavelength_data.iloc[0, 0] != 'Gula Reduksi':\n",
    "    wavelength_data = pd.concat([pd.DataFrame(['Gula Reduksi']), wavelength_data], ignore_index=True)\n",
    "train_data_gula_reduksi_df = pd.DataFrame(train_data_gula_reduksi, columns=wavelength_data[0])\n",
    "test_data_gula_reduksi_df = pd.DataFrame(test_data_gula_reduksi, columns=wavelength_data[0])\n",
    "\n",
    "wavelength_data = pd.read_csv('../raw_data/Wavelenght_NIR.csv', header=None)\n",
    "wavelength_data = wavelength_data.iloc[:train_data_protein.shape[1], :]  # Potong wavelength_data jika perlu\n",
    "# Tambahkan kolom '`KADAR AIR`' jika belum ada\n",
    "if wavelength_data.iloc[0, 0] != 'Kadar Air':\n",
    "    wavelength_data = pd.concat([pd.DataFrame(['Kadar Air']), wavelength_data], ignore_index=True)\n",
    "train_data_kadar_air_df = pd.DataFrame(train_data_kadar_air, columns=wavelength_data[0])\n",
    "test_data_kadar_air_df = pd.DataFrame(test_data_kadar_air, columns=wavelength_data[0])\n",
    "\n",
    "\n",
    "wavelength_data = pd.read_csv('../raw_data/Wavelenght_NIR.csv', header=None)\n",
    "wavelength_data = wavelength_data.iloc[:train_data_protein.shape[1], :]  # Potong wavelength_data jika perlu\n",
    "# Tambahkan kolom 'LEMAK' jika belum ada\n",
    "if wavelength_data.iloc[0, 0] != 'LEMAK':\n",
    "    wavelength_data = pd.concat([pd.DataFrame(['LEMAK']), wavelength_data], ignore_index=True)\n",
    "train_data_lemak_df = pd.DataFrame(train_data_lemak, columns=wavelength_data[0])\n",
    "test_data_lemak_df = pd.DataFrame(test_data_lemak, columns=wavelength_data[0])\n",
    "\n",
    "\n",
    "wavelength_data = pd.read_csv('../raw_data/Wavelenght_NIR.csv', header=None)\n",
    "wavelength_data = wavelength_data.iloc[:train_data_protein.shape[1], :]  # Potong wavelength_data jika perlu\n",
    "# Tambahkan kolom 'PROTEIN' jika belum ada\n",
    "if wavelength_data.iloc[0, 0] != 'PROTEIN':\n",
    "    wavelength_data = pd.concat([pd.DataFrame(['PROTEIN']), wavelength_data], ignore_index=True)\n",
    "train_data_protein_df = pd.DataFrame(train_data_protein, columns=wavelength_data[0])\n",
    "test_data_protein_df = pd.DataFrame(test_data_protein, columns=wavelength_data[0])\n",
    "\n",
    "wavelength_data = pd.read_csv('../raw_data/Wavelenght_NIR.csv', header=None)\n",
    "wavelength_data = wavelength_data.iloc[:train_data_protein.shape[1], :]  # Potong wavelength_data jika perlu\n",
    "# Tambahkan kolom 'FENOL' jika belum ada\n",
    "if wavelength_data.iloc[0, 0] != 'FENOL':\n",
    "    wavelength_data = pd.concat([pd.DataFrame(['FENOL']), wavelength_data], ignore_index=True)\n",
    "train_data_fenol_df = pd.DataFrame(train_data_fenol, columns=wavelength_data[0])\n",
    "test_data_fenol_df = pd.DataFrame(test_data_fenol, columns=wavelength_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7eaf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_outliers_pca_mahalanobis(df, label_col='PROTEIN', n_components=10, variance_threshold=0.95, outlier_percentile=90, plot=True):\n",
    "    # Standarisasi data\n",
    "    scaler = StandardScaler()\n",
    "    X = df.drop(columns=[label_col])\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Lakukan PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Variasi kumulatif\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    num_pc_95 = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "\n",
    "    # Ambil PC yang dibutuhkan\n",
    "    pca_needed = pca_result[:, :num_pc_95]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Hitung mean dan covariance matrix\n",
    "    mean_pca = np.mean(pca_needed, axis=0)\n",
    "    cov_pca = np.cov(pca_needed, rowvar=False)\n",
    "\n",
    "    if cov_pca.ndim == 0:\n",
    "        cov_pca = np.array([[cov_pca]])\n",
    "    elif cov_pca.ndim == 1:\n",
    "        cov_pca = np.diag(cov_pca)\n",
    "\n",
    "    inv_cov_pca = np.linalg.inv(cov_pca)\n",
    "\n",
    "    # Hitung jarak Mahalanobis\n",
    "    distances = np.array([mahalanobis(row, mean_pca, inv_cov_pca) for row in pca_needed])\n",
    "\n",
    "    # Threshold untuk outlier\n",
    "    threshold = np.percentile(distances, outlier_percentile)\n",
    "    outliers = distances > threshold\n",
    "\n",
    "    print(f\"Jumlah PC untuk variasi â‰¥{int(variance_threshold*100)}%: {num_pc_95}\")\n",
    "    print(f\"Jumlah outliers: {np.sum(outliers)}\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(pca_result[:, 0], pca_result[:, 1], c=~outliers, cmap='Accent', label='Data')\n",
    "        plt.scatter(pca_result[outliers, 0], pca_result[outliers, 1], color='red', label='Outliers')\n",
    "        plt.xlabel('PC1')\n",
    "        plt.ylabel('PC2')\n",
    "        plt.title('PCA 2D Plot with Outliers Highlighted')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_kadar_air = detect_outliers_pca_mahalanobis(train_data_kadar_air_df,'Kadar Air')\n",
    "outliers_gula_reduksi = detect_outliers_pca_mahalanobis(train_data_gula_reduksi_df,'Gula Reduksi')\n",
    "outliers_lemak = detect_outliers_pca_mahalanobis(train_data_lemak_df,'LEMAK')\n",
    "outliers_protein = detect_outliers_pca_mahalanobis(train_data_protein_df,'PROTEIN')\n",
    "outliers_fenol = detect_outliers_pca_mahalanobis(train_data_fenol_df,'FENOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32baa88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "output_dir = '../splited_wo_outliers_curated_data_2/basah/nir/kadar_air'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "train_data_kadar_air_df_no_outliers = train_data_kadar_air_df[~outliers_kadar_air]\n",
    "train_data_kadar_air_df_no_outliers.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/kadar_air/cal.csv', index=False)\n",
    "test_data_kadar_air_df.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/kadar_air/val.csv', index=False)\n",
    "\n",
    "# output_dir = '../splited_wo_outliers_curated_data_2/basah/nir/gula_reduksi'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# train_data_gula_reduksi_df_no_outliers = train_data_gula_reduksi_df[~outliers_gula_reduksi]\n",
    "# train_data_gula_reduksi_df_no_outliers.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/gula_reduksi/cal.csv', index=False)\n",
    "# test_data_gula_reduksi_df.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/gula_reduksi/val.csv', index=False)\n",
    "\n",
    "\n",
    "# output_dir = '../splited_wo_outliers_curated_data_2/basah/nir/lemak'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# train_data_lemak_df_no_outliers = train_data_lemak_df[~outliers_lemak]\n",
    "# train_data_lemak_df_no_outliers.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/lemak/cal.csv', index=False)\n",
    "# test_data_lemak_df.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/lemak/val.csv', index=False)\n",
    "\n",
    "\n",
    "# output_dir = '../splited_wo_outliers_curated_data_2/basah/nir/protein'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# train_data_protein_df_no_outliers = train_data_protein_df[~outliers_protein]\n",
    "# train_data_protein_df_no_outliers.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/protein/cal.csv', index=False)\n",
    "# test_data_protein_df.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/protein/val.csv', index=False)\n",
    "\n",
    "# output_dir = '../splited_wo_outliers_curated_data_2/basah/nir/fenol'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# train_data_fenol_df_no_outliers = train_data_fenol_df[~outliers_fenol]\n",
    "# train_data_fenol_df_no_outliers.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/fenol/cal.csv', index=False)\n",
    "# test_data_fenol_df.to_csv('../splited_wo_outliers_curated_data_2/basah/nir/fenol/val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86863c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3e57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
