{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecc9f12",
   "metadata": {},
   "source": [
    "Kadar air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "cal_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/kadar_air/cal.csv'\n",
    "val_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/kadar_air/val.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "cal_df = pd.read_csv(cal_file_path)\n",
    "val_df = pd.read_csv(val_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce924c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools')\n",
    "from preprossesing import mean_norm, max_norm, range_norm, snv, msc, sg1, sg2, smoothing_mean, fd1, fd2\n",
    "\n",
    "# Drop 'Kadar Air' column for preprocessing\n",
    "cal_features = cal_df.drop(columns=['Kadar Air'])\n",
    "val_features = val_df.drop(columns=['Kadar Air'])\n",
    "\n",
    "# Apply preprocessing functions\n",
    "cal_mean_norm = mean_norm(cal_features)\n",
    "val_mean_norm = mean_norm(val_features)\n",
    "\n",
    "cal_max_norm = max_norm(cal_features)\n",
    "val_max_norm = max_norm(val_features)\n",
    "\n",
    "cal_range_norm = range_norm(cal_features)\n",
    "val_range_norm = range_norm(val_features)\n",
    "\n",
    "cal_snv = snv(cal_features)\n",
    "val_snv = snv(val_features)\n",
    "\n",
    "cal_msc = msc(cal_features)\n",
    "val_msc = msc(val_features)\n",
    "\n",
    "cal_sg1 = sg1(cal_features)\n",
    "val_sg1 = sg1(val_features)\n",
    "\n",
    "cal_sg2 = sg2(cal_features)\n",
    "val_sg2 = sg2(val_features)\n",
    "\n",
    "cal_smoothing_mean = smoothing_mean(cal_features,50)\n",
    "val_smoothing_mean = smoothing_mean(val_features,50)\n",
    "\n",
    "cal_fd1 = fd1(cal_sg1)\n",
    "val_fd1 = fd1(val_sg1)\n",
    "\n",
    "cal_fd2 = fd2(cal_sg1)\n",
    "val_fd2 = fd2(val_sg1)\n",
    "\n",
    "# Add 'Kadar Air' column back to the processed data\n",
    "cal_mean_norm['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_mean_norm['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_max_norm['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_max_norm['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_range_norm['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_range_norm['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_snv['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_snv['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_msc['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_msc['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_sg1['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_sg1['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_sg2['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_sg2['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_smoothing_mean['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_smoothing_mean['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_fd1['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_fd1['Kadar Air'] = val_df['Kadar Air']\n",
    "\n",
    "cal_fd2['Kadar Air'] = cal_df['Kadar Air']\n",
    "val_fd2['Kadar Air'] = val_df['Kadar Air']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = '../prepossed_curated_data_2/basah/nir/kadar_air'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the processed data\n",
    "cal_mean_norm.to_csv(os.path.join(output_dir, 'cal_mean_norm.csv'), index=False)\n",
    "val_mean_norm.to_csv(os.path.join(output_dir, 'val_mean_norm.csv'), index=False)\n",
    "\n",
    "cal_max_norm.to_csv(os.path.join(output_dir, 'cal_max_norm.csv'), index=False)\n",
    "val_max_norm.to_csv(os.path.join(output_dir, 'val_max_norm.csv'), index=False)\n",
    "\n",
    "cal_range_norm.to_csv(os.path.join(output_dir, 'cal_range_norm.csv'), index=False)\n",
    "val_range_norm.to_csv(os.path.join(output_dir, 'val_range_norm.csv'), index=False)\n",
    "\n",
    "cal_snv.to_csv(os.path.join(output_dir, 'cal_snv.csv'), index=False)\n",
    "val_snv.to_csv(os.path.join(output_dir, 'val_snv.csv'), index=False)\n",
    "\n",
    "cal_msc.to_csv(os.path.join(output_dir, 'cal_msc.csv'), index=False)\n",
    "val_msc.to_csv(os.path.join(output_dir, 'val_msc.csv'), index=False)\n",
    "\n",
    "cal_sg1.to_csv(os.path.join(output_dir, 'cal_sg1.csv'), index=False)\n",
    "val_sg1.to_csv(os.path.join(output_dir, 'val_sg1.csv'), index=False)\n",
    "\n",
    "cal_sg2.to_csv(os.path.join(output_dir, 'cal_sg2.csv'), index=False)\n",
    "val_sg2.to_csv(os.path.join(output_dir, 'val_sg2.csv'), index=False)\n",
    "\n",
    "cal_smoothing_mean.to_csv(os.path.join(output_dir, 'cal_smoothing_mean.csv'), index=False)\n",
    "val_smoothing_mean.to_csv(os.path.join(output_dir, 'val_smoothing_mean.csv'), index=False)\n",
    "\n",
    "cal_fd1.to_csv(os.path.join(output_dir, 'cal_fd1.csv'), index=False)\n",
    "val_fd1.to_csv(os.path.join(output_dir, 'val_fd1.csv'), index=False)\n",
    "\n",
    "cal_fd2.to_csv(os.path.join(output_dir, 'cal_fd2.csv'), index=False)\n",
    "val_fd2.to_csv(os.path.join(output_dir, 'val_fd2.csv'), index=False)\n",
    "\n",
    "cal_df.to_csv(os.path.join(output_dir, 'cal_ori.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val_ori.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de36a1a",
   "metadata": {},
   "source": [
    "Gula reduksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "cal_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/gula_reduksi/cal.csv'\n",
    "val_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/gula_reduksi/val.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "cal_df = pd.read_csv(cal_file_path)\n",
    "val_df = pd.read_csv(val_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools')\n",
    "from preprossesing import mean_norm, max_norm, range_norm, snv, msc, sg1, sg2, smoothing_mean, fd1, fd2\n",
    "\n",
    "# Drop 'Gula Reduksi' column for preprocessing\n",
    "cal_features = cal_df.drop(columns=['Gula Reduksi'])\n",
    "val_features = val_df.drop(columns=['Gula Reduksi'])\n",
    "\n",
    "# Apply preprocessing functions\n",
    "cal_mean_norm = mean_norm(cal_features)\n",
    "val_mean_norm = mean_norm(val_features)\n",
    "\n",
    "cal_max_norm = max_norm(cal_features)\n",
    "val_max_norm = max_norm(val_features)\n",
    "\n",
    "cal_range_norm = range_norm(cal_features)\n",
    "val_range_norm = range_norm(val_features)\n",
    "\n",
    "cal_snv = snv(cal_features)\n",
    "val_snv = snv(val_features)\n",
    "\n",
    "cal_msc = msc(cal_features)\n",
    "val_msc = msc(val_features)\n",
    "\n",
    "cal_sg1 = sg1(cal_features)\n",
    "val_sg1 = sg1(val_features)\n",
    "\n",
    "cal_sg2 = sg2(cal_features)\n",
    "val_sg2 = sg2(val_features)\n",
    "\n",
    "cal_smoothing_mean = smoothing_mean(cal_features,50)\n",
    "val_smoothing_mean = smoothing_mean(val_features,50)\n",
    "\n",
    "cal_fd1 = fd1(cal_sg1)\n",
    "val_fd1 = fd1(val_sg1)\n",
    "\n",
    "cal_fd2 = fd2(cal_sg1)\n",
    "val_fd2 = fd2(val_sg1)\n",
    "\n",
    "# Add 'Gula Reduksi' column back to the processed data\n",
    "cal_mean_norm['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_mean_norm['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_max_norm['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_max_norm['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_range_norm['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_range_norm['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_snv['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_snv['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_msc['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_msc['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_sg1['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_sg1['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_sg2['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_sg2['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_smoothing_mean['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_smoothing_mean['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_fd1['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_fd1['Gula Reduksi'] = val_df['Gula Reduksi']\n",
    "\n",
    "cal_fd2['Gula Reduksi'] = cal_df['Gula Reduksi']\n",
    "val_fd2['Gula Reduksi'] = val_df['Gula Reduksi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a384231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = '../prepossed_curated_data_2/basah/nir/gula_reduksi'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the processed data\n",
    "cal_mean_norm.to_csv(os.path.join(output_dir, 'cal_mean_norm.csv'), index=False)\n",
    "val_mean_norm.to_csv(os.path.join(output_dir, 'val_mean_norm.csv'), index=False)\n",
    "\n",
    "cal_max_norm.to_csv(os.path.join(output_dir, 'cal_max_norm.csv'), index=False)\n",
    "val_max_norm.to_csv(os.path.join(output_dir, 'val_max_norm.csv'), index=False)\n",
    "\n",
    "cal_range_norm.to_csv(os.path.join(output_dir, 'cal_range_norm.csv'), index=False)\n",
    "val_range_norm.to_csv(os.path.join(output_dir, 'val_range_norm.csv'), index=False)\n",
    "\n",
    "cal_snv.to_csv(os.path.join(output_dir, 'cal_snv.csv'), index=False)\n",
    "val_snv.to_csv(os.path.join(output_dir, 'val_snv.csv'), index=False)\n",
    "\n",
    "cal_msc.to_csv(os.path.join(output_dir, 'cal_msc.csv'), index=False)\n",
    "val_msc.to_csv(os.path.join(output_dir, 'val_msc.csv'), index=False)\n",
    "\n",
    "cal_sg1.to_csv(os.path.join(output_dir, 'cal_sg1.csv'), index=False)\n",
    "val_sg1.to_csv(os.path.join(output_dir, 'val_sg1.csv'), index=False)\n",
    "\n",
    "cal_sg2.to_csv(os.path.join(output_dir, 'cal_sg2.csv'), index=False)\n",
    "val_sg2.to_csv(os.path.join(output_dir, 'val_sg2.csv'), index=False)\n",
    "\n",
    "cal_smoothing_mean.to_csv(os.path.join(output_dir, 'cal_smoothing_mean.csv'), index=False)\n",
    "val_smoothing_mean.to_csv(os.path.join(output_dir, 'val_smoothing_mean.csv'), index=False)\n",
    "\n",
    "cal_fd1.to_csv(os.path.join(output_dir, 'cal_fd1.csv'), index=False)\n",
    "val_fd1.to_csv(os.path.join(output_dir, 'val_fd1.csv'), index=False)\n",
    "\n",
    "cal_fd2.to_csv(os.path.join(output_dir, 'cal_fd2.csv'), index=False)\n",
    "val_fd2.to_csv(os.path.join(output_dir, 'val_fd2.csv'), index=False)\n",
    "\n",
    "cal_df.to_csv(os.path.join(output_dir, 'cal_ori.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val_ori.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff79205",
   "metadata": {},
   "source": [
    "protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "cal_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/protein/cal.csv'\n",
    "val_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/protein/val.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "cal_df = pd.read_csv(cal_file_path)\n",
    "val_df = pd.read_csv(val_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools')\n",
    "from preprossesing import mean_norm, max_norm, range_norm, snv, msc, sg1, sg2, smoothing_mean, fd1, fd2\n",
    "\n",
    "# Drop 'PROTEIN' column for preprocessing\n",
    "cal_features = cal_df.drop(columns=['PROTEIN'])\n",
    "val_features = val_df.drop(columns=['PROTEIN'])\n",
    "\n",
    "# Apply preprocessing functions\n",
    "cal_mean_norm = mean_norm(cal_features)\n",
    "val_mean_norm = mean_norm(val_features)\n",
    "\n",
    "cal_max_norm = max_norm(cal_features)\n",
    "val_max_norm = max_norm(val_features)\n",
    "\n",
    "cal_range_norm = range_norm(cal_features)\n",
    "val_range_norm = range_norm(val_features)\n",
    "\n",
    "cal_snv = snv(cal_features)\n",
    "val_snv = snv(val_features)\n",
    "\n",
    "cal_msc = msc(cal_features)\n",
    "val_msc = msc(val_features)\n",
    "\n",
    "cal_sg1 = sg1(cal_features)\n",
    "val_sg1 = sg1(val_features)\n",
    "\n",
    "cal_sg2 = sg2(cal_features)\n",
    "val_sg2 = sg2(val_features)\n",
    "\n",
    "cal_smoothing_mean = smoothing_mean(cal_features,50)\n",
    "val_smoothing_mean = smoothing_mean(val_features,50)\n",
    "\n",
    "cal_fd1 = fd1(cal_sg1)\n",
    "val_fd1 = fd1(val_sg1)\n",
    "\n",
    "cal_fd2 = fd2(cal_sg1)\n",
    "val_fd2 = fd2(val_sg1)\n",
    "\n",
    "# Add 'PROTEIN' column back to the processed data\n",
    "cal_mean_norm['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_mean_norm['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_max_norm['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_max_norm['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_range_norm['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_range_norm['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_snv['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_snv['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_msc['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_msc['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_sg1['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_sg1['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_sg2['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_sg2['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_smoothing_mean['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_smoothing_mean['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_fd1['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_fd1['PROTEIN'] = val_df['PROTEIN']\n",
    "\n",
    "cal_fd2['PROTEIN'] = cal_df['PROTEIN']\n",
    "val_fd2['PROTEIN'] = val_df['PROTEIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051535dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = '../prepossed_curated_data_2/basah/nir/protein'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the processed data\n",
    "cal_mean_norm.to_csv(os.path.join(output_dir, 'cal_mean_norm.csv'), index=False)\n",
    "val_mean_norm.to_csv(os.path.join(output_dir, 'val_mean_norm.csv'), index=False)\n",
    "\n",
    "cal_max_norm.to_csv(os.path.join(output_dir, 'cal_max_norm.csv'), index=False)\n",
    "val_max_norm.to_csv(os.path.join(output_dir, 'val_max_norm.csv'), index=False)\n",
    "\n",
    "cal_range_norm.to_csv(os.path.join(output_dir, 'cal_range_norm.csv'), index=False)\n",
    "val_range_norm.to_csv(os.path.join(output_dir, 'val_range_norm.csv'), index=False)\n",
    "\n",
    "cal_snv.to_csv(os.path.join(output_dir, 'cal_snv.csv'), index=False)\n",
    "val_snv.to_csv(os.path.join(output_dir, 'val_snv.csv'), index=False)\n",
    "\n",
    "cal_msc.to_csv(os.path.join(output_dir, 'cal_msc.csv'), index=False)\n",
    "val_msc.to_csv(os.path.join(output_dir, 'val_msc.csv'), index=False)\n",
    "\n",
    "cal_sg1.to_csv(os.path.join(output_dir, 'cal_sg1.csv'), index=False)\n",
    "val_sg1.to_csv(os.path.join(output_dir, 'val_sg1.csv'), index=False)\n",
    "\n",
    "cal_sg2.to_csv(os.path.join(output_dir, 'cal_sg2.csv'), index=False)\n",
    "val_sg2.to_csv(os.path.join(output_dir, 'val_sg2.csv'), index=False)\n",
    "\n",
    "cal_smoothing_mean.to_csv(os.path.join(output_dir, 'cal_smoothing_mean.csv'), index=False)\n",
    "val_smoothing_mean.to_csv(os.path.join(output_dir, 'val_smoothing_mean.csv'), index=False)\n",
    "\n",
    "cal_fd1.to_csv(os.path.join(output_dir, 'cal_fd1.csv'), index=False)\n",
    "val_fd1.to_csv(os.path.join(output_dir, 'val_fd1.csv'), index=False)\n",
    "\n",
    "cal_fd2.to_csv(os.path.join(output_dir, 'cal_fd2.csv'), index=False)\n",
    "val_fd2.to_csv(os.path.join(output_dir, 'val_fd2.csv'), index=False)\n",
    "\n",
    "cal_df.to_csv(os.path.join(output_dir, 'cal_ori.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val_ori.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19dd055",
   "metadata": {},
   "source": [
    "LEMAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89df93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "cal_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/lemak/cal.csv'\n",
    "val_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/lemak/val.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "cal_df = pd.read_csv(cal_file_path)\n",
    "val_df = pd.read_csv(val_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools')\n",
    "from preprossesing import mean_norm, max_norm, range_norm, snv, msc, sg1, sg2, smoothing_mean, fd1, fd2\n",
    "\n",
    "# Drop 'LEMAK' column for preprocessing\n",
    "cal_features = cal_df.drop(columns=['LEMAK'])\n",
    "val_features = val_df.drop(columns=['LEMAK'])\n",
    "\n",
    "# Apply preprocessing functions\n",
    "cal_mean_norm = mean_norm(cal_features)\n",
    "val_mean_norm = mean_norm(val_features)\n",
    "\n",
    "cal_max_norm = max_norm(cal_features)\n",
    "val_max_norm = max_norm(val_features)\n",
    "\n",
    "cal_range_norm = range_norm(cal_features)\n",
    "val_range_norm = range_norm(val_features)\n",
    "\n",
    "cal_snv = snv(cal_features)\n",
    "val_snv = snv(val_features)\n",
    "\n",
    "cal_msc = msc(cal_features)\n",
    "val_msc = msc(val_features)\n",
    "\n",
    "cal_sg1 = sg1(cal_features)\n",
    "val_sg1 = sg1(val_features)\n",
    "\n",
    "cal_sg2 = sg2(cal_features)\n",
    "val_sg2 = sg2(val_features)\n",
    "\n",
    "cal_smoothing_mean = smoothing_mean(cal_features,50)\n",
    "val_smoothing_mean = smoothing_mean(val_features,50)\n",
    "\n",
    "cal_fd1 = fd1(cal_sg1)\n",
    "val_fd1 = fd1(val_sg1)\n",
    "\n",
    "cal_fd2 = fd2(cal_sg1)\n",
    "val_fd2 = fd2(val_sg1)\n",
    "\n",
    "# Add 'LEMAK' column back to the processed data\n",
    "cal_mean_norm['LEMAK'] = cal_df['LEMAK']\n",
    "val_mean_norm['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_max_norm['LEMAK'] = cal_df['LEMAK']\n",
    "val_max_norm['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_range_norm['LEMAK'] = cal_df['LEMAK']\n",
    "val_range_norm['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_snv['LEMAK'] = cal_df['LEMAK']\n",
    "val_snv['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_msc['LEMAK'] = cal_df['LEMAK']\n",
    "val_msc['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_sg1['LEMAK'] = cal_df['LEMAK']\n",
    "val_sg1['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_sg2['LEMAK'] = cal_df['LEMAK']\n",
    "val_sg2['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_smoothing_mean['LEMAK'] = cal_df['LEMAK']\n",
    "val_smoothing_mean['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_fd1['LEMAK'] = cal_df['LEMAK']\n",
    "val_fd1['LEMAK'] = val_df['LEMAK']\n",
    "\n",
    "cal_fd2['LEMAK'] = cal_df['LEMAK']\n",
    "val_fd2['LEMAK'] = val_df['LEMAK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = '../prepossed_curated_data_2/basah/nir/lemak'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the processed data\n",
    "cal_mean_norm.to_csv(os.path.join(output_dir, 'cal_mean_norm.csv'), index=False)\n",
    "val_mean_norm.to_csv(os.path.join(output_dir, 'val_mean_norm.csv'), index=False)\n",
    "\n",
    "cal_max_norm.to_csv(os.path.join(output_dir, 'cal_max_norm.csv'), index=False)\n",
    "val_max_norm.to_csv(os.path.join(output_dir, 'val_max_norm.csv'), index=False)\n",
    "\n",
    "cal_range_norm.to_csv(os.path.join(output_dir, 'cal_range_norm.csv'), index=False)\n",
    "val_range_norm.to_csv(os.path.join(output_dir, 'val_range_norm.csv'), index=False)\n",
    "\n",
    "cal_snv.to_csv(os.path.join(output_dir, 'cal_snv.csv'), index=False)\n",
    "val_snv.to_csv(os.path.join(output_dir, 'val_snv.csv'), index=False)\n",
    "\n",
    "cal_msc.to_csv(os.path.join(output_dir, 'cal_msc.csv'), index=False)\n",
    "val_msc.to_csv(os.path.join(output_dir, 'val_msc.csv'), index=False)\n",
    "\n",
    "cal_sg1.to_csv(os.path.join(output_dir, 'cal_sg1.csv'), index=False)\n",
    "val_sg1.to_csv(os.path.join(output_dir, 'val_sg1.csv'), index=False)\n",
    "\n",
    "cal_sg2.to_csv(os.path.join(output_dir, 'cal_sg2.csv'), index=False)\n",
    "val_sg2.to_csv(os.path.join(output_dir, 'val_sg2.csv'), index=False)\n",
    "\n",
    "cal_smoothing_mean.to_csv(os.path.join(output_dir, 'cal_smoothing_mean.csv'), index=False)\n",
    "val_smoothing_mean.to_csv(os.path.join(output_dir, 'val_smoothing_mean.csv'), index=False)\n",
    "\n",
    "cal_fd1.to_csv(os.path.join(output_dir, 'cal_fd1.csv'), index=False)\n",
    "val_fd1.to_csv(os.path.join(output_dir, 'val_fd1.csv'), index=False)\n",
    "\n",
    "cal_fd2.to_csv(os.path.join(output_dir, 'cal_fd2.csv'), index=False)\n",
    "val_fd2.to_csv(os.path.join(output_dir, 'val_fd2.csv'), index=False)\n",
    "\n",
    "cal_df.to_csv(os.path.join(output_dir, 'cal_ori.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val_ori.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f9256",
   "metadata": {},
   "source": [
    "FENOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "cal_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/fenol/cal.csv'\n",
    "val_file_path = '../splited_wo_outliers_curated_data_2/basah/nir/fenol/val.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "cal_df = pd.read_csv(cal_file_path)\n",
    "val_df = pd.read_csv(val_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools')\n",
    "from preprossesing import mean_norm, max_norm, range_norm, snv, msc, sg1, sg2, smoothing_mean, fd1, fd2\n",
    "\n",
    "# Drop 'FENOL' column for preprocessing\n",
    "cal_features = cal_df.drop(columns=['FENOL'])\n",
    "val_features = val_df.drop(columns=['FENOL'])\n",
    "\n",
    "# Apply preprocessing functions\n",
    "cal_mean_norm = mean_norm(cal_features)\n",
    "val_mean_norm = mean_norm(val_features)\n",
    "\n",
    "cal_max_norm = max_norm(cal_features)\n",
    "val_max_norm = max_norm(val_features)\n",
    "\n",
    "cal_range_norm = range_norm(cal_features)\n",
    "val_range_norm = range_norm(val_features)\n",
    "\n",
    "cal_snv = snv(cal_features)\n",
    "val_snv = snv(val_features)\n",
    "\n",
    "cal_msc = msc(cal_features)\n",
    "val_msc = msc(val_features)\n",
    "\n",
    "cal_sg1 = sg1(cal_features)\n",
    "val_sg1 = sg1(val_features)\n",
    "\n",
    "cal_sg2 = sg2(cal_features)\n",
    "val_sg2 = sg2(val_features)\n",
    "\n",
    "cal_smoothing_mean = smoothing_mean(cal_features,50)\n",
    "val_smoothing_mean = smoothing_mean(val_features,50)\n",
    "\n",
    "cal_fd1 = fd1(cal_sg1)\n",
    "val_fd1 = fd1(val_sg1)\n",
    "\n",
    "cal_fd2 = fd2(cal_sg1)\n",
    "val_fd2 = fd2(val_sg1)\n",
    "\n",
    "# Add 'FENOL' column back to the processed data\n",
    "cal_mean_norm['FENOL'] = cal_df['FENOL']\n",
    "val_mean_norm['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_max_norm['FENOL'] = cal_df['FENOL']\n",
    "val_max_norm['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_range_norm['FENOL'] = cal_df['FENOL']\n",
    "val_range_norm['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_snv['FENOL'] = cal_df['FENOL']\n",
    "val_snv['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_msc['FENOL'] = cal_df['FENOL']\n",
    "val_msc['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_sg1['FENOL'] = cal_df['FENOL']\n",
    "val_sg1['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_sg2['FENOL'] = cal_df['FENOL']\n",
    "val_sg2['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_smoothing_mean['FENOL'] = cal_df['FENOL']\n",
    "val_smoothing_mean['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_fd1['FENOL'] = cal_df['FENOL']\n",
    "val_fd1['FENOL'] = val_df['FENOL']\n",
    "\n",
    "cal_fd2['FENOL'] = cal_df['FENOL']\n",
    "val_fd2['FENOL'] = val_df['FENOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6889be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = '../prepossed_curated_data_2/basah/nir/fenol'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the processed data\n",
    "cal_mean_norm.to_csv(os.path.join(output_dir, 'cal_mean_norm.csv'), index=False)\n",
    "val_mean_norm.to_csv(os.path.join(output_dir, 'val_mean_norm.csv'), index=False)\n",
    "\n",
    "cal_max_norm.to_csv(os.path.join(output_dir, 'cal_max_norm.csv'), index=False)\n",
    "val_max_norm.to_csv(os.path.join(output_dir, 'val_max_norm.csv'), index=False)\n",
    "\n",
    "cal_range_norm.to_csv(os.path.join(output_dir, 'cal_range_norm.csv'), index=False)\n",
    "val_range_norm.to_csv(os.path.join(output_dir, 'val_range_norm.csv'), index=False)\n",
    "\n",
    "cal_snv.to_csv(os.path.join(output_dir, 'cal_snv.csv'), index=False)\n",
    "val_snv.to_csv(os.path.join(output_dir, 'val_snv.csv'), index=False)\n",
    "\n",
    "cal_msc.to_csv(os.path.join(output_dir, 'cal_msc.csv'), index=False)\n",
    "val_msc.to_csv(os.path.join(output_dir, 'val_msc.csv'), index=False)\n",
    "\n",
    "cal_sg1.to_csv(os.path.join(output_dir, 'cal_sg1.csv'), index=False)\n",
    "val_sg1.to_csv(os.path.join(output_dir, 'val_sg1.csv'), index=False)\n",
    "\n",
    "cal_sg2.to_csv(os.path.join(output_dir, 'cal_sg2.csv'), index=False)\n",
    "val_sg2.to_csv(os.path.join(output_dir, 'val_sg2.csv'), index=False)\n",
    "\n",
    "cal_smoothing_mean.to_csv(os.path.join(output_dir, 'cal_smoothing_mean.csv'), index=False)\n",
    "val_smoothing_mean.to_csv(os.path.join(output_dir, 'val_smoothing_mean.csv'), index=False)\n",
    "\n",
    "cal_fd1.to_csv(os.path.join(output_dir, 'cal_fd1.csv'), index=False)\n",
    "val_fd1.to_csv(os.path.join(output_dir, 'val_fd1.csv'), index=False)\n",
    "\n",
    "cal_fd2.to_csv(os.path.join(output_dir, 'cal_fd2.csv'), index=False)\n",
    "val_fd2.to_csv(os.path.join(output_dir, 'val_fd2.csv'), index=False)\n",
    "\n",
    "cal_df.to_csv(os.path.join(output_dir, 'cal_ori.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val_ori.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
